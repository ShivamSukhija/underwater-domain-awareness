{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt-vQAyphOZJ",
        "outputId": "1fc15149-05c6-4342-96a1-2d620ca56dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gmVNzq-gzCK",
        "outputId": "4ffd57bd-619d-4c58-f371-77965be40cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 60 wav files to process.\n",
            "[1/60] Processed S2_Test_001.wav -> Found 38 segments.\n",
            "[2/60] Processed S2_Test_003.wav -> Found 20 segments.\n",
            "[3/60] Processed S2_Test_002.wav -> Found 24 segments.\n",
            "[4/60] Processed S2_Test_004.wav -> Found 40 segments.\n",
            "[5/60] Processed S2_Test_006.wav -> Found 18 segments.\n",
            "[6/60] Processed S2_Test_005.wav -> Found 50 segments.\n",
            "[7/60] Processed S2_Test_007.wav -> Found 36 segments.\n",
            "[8/60] Processed S2_Test_008.wav -> Found 36 segments.\n",
            "[9/60] Processed S2_Test_009.wav -> Found 50 segments.\n",
            "[10/60] Processed S2_Test_012.wav -> Found 36 segments.\n",
            "[11/60] Processed S2_Test_011.wav -> Found 24 segments.\n",
            "[12/60] Processed S2_Test_014.wav -> Found 9 segments.\n",
            "[13/60] Processed S2_Test_015.wav -> Found 30 segments.\n",
            "[14/60] Processed S2_Test_013.wav -> Found 18 segments.\n",
            "[15/60] Processed S2_Test_010.wav -> Found 20 segments.\n",
            "[16/60] Processed S2_Test_016.wav -> Found 24 segments.\n",
            "[17/60] Processed S2_Test_017.wav -> Found 26 segments.\n",
            "[18/60] Processed S2_Test_018.wav -> Found 30 segments.\n",
            "[19/60] Processed S2_Test_019.wav -> Found 32 segments.\n",
            "[20/60] Processed S2_Test_020.wav -> Found 18 segments.\n",
            "[21/60] Processed S2_Test_021.wav -> Found 20 segments.\n",
            "[22/60] Processed S2_Test_022.wav -> Found 30 segments.\n",
            "[23/60] Processed S2_Test_023.wav -> Found 36 segments.\n",
            "[24/60] Processed S2_Test_024.wav -> Found 40 segments.\n",
            "[25/60] Processed S2_Test_025.wav -> Found 10 segments.\n",
            "[26/60] Processed S2_Test_026.wav -> Found 45 segments.\n",
            "[27/60] Processed S2_Test_027.wav -> Found 42 segments.\n",
            "[28/60] Processed S2_Test_030.wav -> Found 60 segments.\n",
            "[29/60] Processed S2_Test_028.wav -> Found 30 segments.\n",
            "[30/60] Processed S2_Test_032.wav -> Found 30 segments.\n",
            "[31/60] Processed S2_Test_031.wav -> Found 24 segments.\n",
            "[32/60] Processed S2_Test_029.wav -> Found 50 segments.\n",
            "[33/60] Processed S2_Test_033.wav -> Found 10 segments.\n",
            "[34/60] Processed S2_Test_034.wav -> Found 10 segments.\n",
            "[35/60] Processed S2_Test_035.wav -> Found 128 segments.\n",
            "[36/60] Processed S2_Test_038.wav -> Found 12 segments.\n",
            "[37/60] Processed S2_Test_039.wav -> Found 18 segments.\n",
            "[38/60] Processed S2_Test_036.wav -> Found 20 segments.\n",
            "[39/60] Processed S2_Test_037.wav -> Found 18 segments.\n",
            "[40/60] Processed S2_Test_041.wav -> Found 15 segments.\n",
            "[41/60] Processed S2_Test_040.wav -> Found 18 segments.\n",
            "[42/60] Processed S2_Test_045.wav -> Found 15 segments.\n",
            "[43/60] Processed S2_Test_046.wav -> Found 48 segments.\n",
            "[44/60] Processed S2_Test_043.wav -> Found 6 segments.\n",
            "[45/60] Processed S2_Test_044.wav -> Found 12 segments.\n",
            "[46/60] Processed S2_Test_042.wav -> Found 40 segments.\n",
            "[47/60] Processed S2_Test_047.wav -> Found 24 segments.\n",
            "[48/60] Processed S2_Test_050.wav -> Found 22 segments.\n",
            "[49/60] Processed S2_Test_048.wav -> Found 20 segments.\n",
            "[50/60] Processed S2_Test_049.wav -> Found 30 segments.\n",
            "[51/60] Processed S2_Test_052.wav -> Found 12 segments.\n",
            "[52/60] Processed S2_Test_051.wav -> Found 42 segments.\n",
            "[53/60] Processed S2_Test_053.wav -> Found 30 segments.\n",
            "[54/60] Processed S2_Test_054.wav -> Found 36 segments.\n",
            "[55/60] Processed S2_Test_055.wav -> Found 40 segments.\n",
            "[56/60] Processed S2_Test_056.wav -> Found 35 segments.\n",
            "[57/60] Processed S2_Test_057.wav -> Found 30 segments.\n",
            "[58/60] Processed S2_Test_058.wav -> Found 45 segments.\n",
            "[59/60] Processed S2_Test_059.wav -> Found 54 segments.\n",
            "[60/60] Processed S2_Test_060.wav -> Found 14 segments.\n",
            "\n",
            "✅ Successfully generated submission file: 2025_11_03_YOURTEAM_PS12.json\n",
            "Total audio files processed: 60\n",
            "Total annotations generated: 1800\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import librosa\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "from model import CNNWithGAP\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/best_cnn.pth\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNNWithGAP(n_classes=4).to(DEVICE)\n",
        "# Check if model file exists before loading\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "else:\n",
        "    print(f\"Warning: Model file not found at {MODEL_PATH}. Using an untrained model.\")\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Segmentation + Prediction\n",
        "# -----------------------------\n",
        "def segment_and_predict(y, sr, model, segment_length=10, hop_length=10, conf_threshold=0.3):\n",
        "    \"\"\"\n",
        "    Processes an audio signal, segments it, and returns predictions.\n",
        "    Note: Takes the audio waveform 'y' as input directly.\n",
        "    \"\"\"\n",
        "    seg_samples = int(segment_length * sr)\n",
        "    hop_samples = int(hop_length * sr)\n",
        "\n",
        "    results = []\n",
        "    # Process the audio in segments\n",
        "    for start in range(0, len(y) - seg_samples + 1, hop_samples):\n",
        "        end = start + seg_samples\n",
        "        seg_y = y[start:end]\n",
        "\n",
        "        # Feature extraction: Mel spectrogram\n",
        "        mel = librosa.feature.melspectrogram(y=seg_y, sr=sr, n_mels=128)\n",
        "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "        # Prepare tensor for the model\n",
        "        X = torch.tensor(mel_db, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        # Get model prediction\n",
        "        with torch.no_grad():\n",
        "            out = model(X)\n",
        "            probs = F.softmax(out, dim=1).cpu().numpy()[0]\n",
        "\n",
        "            # --- Applying adjustments to probabilities ---\n",
        "            probs[1] *= 1.5  # marine_animal\n",
        "            probs[2] *= 1.5  # natural_sound\n",
        "            probs[3] *= 1.5  # other_anthropogenic\n",
        "            probs /= probs.sum() # Re-normalize probabilities\n",
        "\n",
        "        pred_id = int(np.argmax(probs)) + 1  # 1-based indexing for categories\n",
        "        conf = float(probs[pred_id - 1])\n",
        "\n",
        "        # Store result if confidence is above the threshold\n",
        "        if conf >= conf_threshold:\n",
        "            results.append({\n",
        "                \"category_id\": pred_id,\n",
        "                \"start_time\": round(start / sr, 3),\n",
        "                \"end_time\": round(end / sr, 3),\n",
        "                \"duration\": round((end - start) / sr, 3),\n",
        "                \"score\": conf\n",
        "            })\n",
        "    return results\n",
        "\n",
        "# -----------------------------\n",
        "# Build JSON file\n",
        "# -----------------------------\n",
        "\n",
        "today = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "output_file = \"output.json\"\n",
        "\n",
        "\n",
        "TEST_AUDIO_DIR = \"/content/gdrive/MyDrive/20251103\"\n",
        "\n",
        "# Initialize the main submission dictionary with all required keys\n",
        "submission = {\n",
        "    \"audios\": [],\n",
        "    \"categories\": [\n",
        "        {\"id\": 1, \"name\": \"vessel\"},\n",
        "        {\"id\": 2, \"name\": \"marine_animal\"},\n",
        "        {\"id\": 3, \"name\": \"natural_sound\"},\n",
        "        {\"id\": 4, \"name\": \"other_anthropogenic\"}\n",
        "    ],\n",
        "    \"annotations\": []\n",
        "}\n",
        "\n",
        "# Recursively find all .wav files in the test directory\n",
        "wav_files = glob.glob(os.path.join(TEST_AUDIO_DIR, \"**\", \"*.wav\"), recursive=True)\n",
        "if not wav_files:\n",
        "    print(f\"Error: No .wav files found in {TEST_AUDIO_DIR}. Please check the path.\")\n",
        "else:\n",
        "    print(f\"Found {len(wav_files)} wav files to process.\")\n",
        "\n",
        "# Initialize a global counter for unique annotation IDs\n",
        "annotation_id_counter = 1\n",
        "\n",
        "# Process each audio file\n",
        "for audio_id, file_path in enumerate(wav_files, 1):\n",
        "    try:\n",
        "        # Load audio file and get its total duration\n",
        "        y, sr = librosa.load(file_path, sr=48000, mono=True)\n",
        "        total_duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "        # Add audio file information to the \"audios\" list\n",
        "        submission[\"audios\"].append({\n",
        "            \"id\": audio_id,\n",
        "            \"file_name\": os.path.basename(file_path),\n",
        "            \"file_path\": file_path,  # Storing the full path for reference\n",
        "            \"duration\": round(total_duration, 4)\n",
        "        })\n",
        "\n",
        "        # Get segment predictions for the loaded audio\n",
        "        annotations = segment_and_predict(y, sr, model, conf_threshold=0.3)\n",
        "\n",
        "        # Add the results to the main \"annotations\" list\n",
        "        for ann in annotations:\n",
        "            ann[\"id\"] = annotation_id_counter\n",
        "            ann[\"audio_id\"] = audio_id  # Link annotation to the audio file\n",
        "            submission[\"annotations\"].append(ann)\n",
        "            annotation_id_counter += 1\n",
        "\n",
        "        print(f\"[{audio_id}/{len(wav_files)}] Processed {os.path.basename(file_path)} -> Found {len(annotations)} segments.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "\n",
        "# Save the final JSON file\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(submission, f, indent=4)\n",
        "\n",
        "print(f\"\\n✅ Successfully generated submission file: {output_file}\")\n",
        "print(f\"Total audio files processed: {len(submission['audios'])}\")\n",
        "print(f\"Total annotations generated: {len(submission['annotations'])}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
